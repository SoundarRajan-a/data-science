{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXWs9DNKwM29",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ===== CUSTOMER PURCHASE FREQUENCY ANALYSIS =====\n",
        "\n",
        "# 1. DATA LOADING AND EXPLORATION\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import gradio as gr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset (replace with actual data source)\n",
        "# df = pd.read_csv('customer_data.csv')\n",
        "\n",
        "# For demonstration, create a sample dataset\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'customer_id': range(1, n_samples + 1),\n",
        "    'age': np.random.randint(18, 80, n_samples),\n",
        "    'gender': np.random.choice(['M', 'F'], n_samples),\n",
        "    'total_purchases': np.random.randint(1, 100, n_samples),\n",
        "    'total_spend': np.random.randint(100, 10000, n_samples),\n",
        "    'avg_order_value': np.random.randint(20, 500, n_samples),\n",
        "    'customer_tenure_months': np.random.randint(1, 120, n_samples),\n",
        "    'website_visits': np.random.randint(0, 500, n_samples),\n",
        "    'cart_abandonment_rate': np.random.uniform(0, 100, n_samples),\n",
        "    'product_preference': np.random.choice(['Electronics', 'Fashion', 'Home', 'Beauty'], n_samples),\n",
        "    'device_type': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n_samples),\n",
        "    'newsletter_subscribed': np.random.choice(['Yes', 'No'], n_samples),\n",
        "    'customer_reviews': np.random.randint(0, 50, n_samples),\n",
        "    'last_purchase_days_ago': np.random.randint(0, 365, n_samples)\n",
        "})\n",
        "\n",
        "# Create target variable based on total purchases\n",
        "def categorize_frequency(purchases):\n",
        "    if purchases < 5:\n",
        "        return 'Rare'\n",
        "    elif purchases < 15:\n",
        "        return 'Occasional'\n",
        "    elif purchases < 40:\n",
        "        return 'Regular'\n",
        "    else:\n",
        "        return 'Frequent'\n",
        "\n",
        "df['purchase_frequency'] = df['total_purchases'].apply(categorize_frequency)\n",
        "\n",
        "# Display basic info\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst Few Rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nData Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
        "\n",
        "# ===== EXPLORATORY DATA ANALYSIS =====\n",
        "\n",
        "# 1. Distribution of Purchase Frequency\n",
        "plt.figure(figsize=(10, 5))\n",
        "df['purchase_frequency'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribution of Customer Purchase Frequency')\n",
        "plt.xlabel('Frequency Category')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# 2. Age Distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['age'], kde=True, color='green')\n",
        "plt.title('Distribution of Customer Age')\n",
        "plt.xlabel('Age')\n",
        "plt.show()\n",
        "\n",
        "# 3. Total Spend Distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['total_spend'], kde=True, color='orange')\n",
        "plt.title('Distribution of Total Customer Spend')\n",
        "plt.xlabel('Total Spend ($)')\n",
        "plt.show()\n",
        "\n",
        "# 4. Relationship between Total Spend and Purchase Frequency\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='purchase_frequency', y='total_spend', data=df)\n",
        "plt.title('Total Spend by Purchase Frequency Category')\n",
        "plt.xlabel('Purchase Frequency')\n",
        "plt.ylabel('Total Spend ($)')\n",
        "plt.show()\n",
        "\n",
        "# 5. Correlation Heatmap\n",
        "numeric_df = df[['age', 'total_purchases', 'total_spend', 'avg_order_value',\n",
        "                   'customer_tenure_months', 'website_visits', 'cart_abandonment_rate']]\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap of Numeric Features')\n",
        "plt.show()\n",
        "\n",
        "# 6. Customer Tenure vs Purchase Frequency\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='purchase_frequency', y='customer_tenure_months', data=df)\n",
        "plt.title('Customer Tenure by Purchase Frequency Category')\n",
        "plt.xlabel('Purchase Frequency')\n",
        "plt.ylabel('Tenure (Months)')\n",
        "plt.show()\n",
        "\n",
        "# ===== FEATURE ENGINEERING =====\n",
        "\n",
        "# Create new features\n",
        "df['customer_lifetime_value'] = df['total_spend'] / (df['customer_tenure_months'] + 1)\n",
        "df['purchase_velocity'] = df['total_purchases'] / (df['customer_tenure_months'] + 1)\n",
        "df['recent_purchase'] = (df['last_purchase_days_ago'] <= 30).astype(int)\n",
        "df['review_engagement_rate'] = df['customer_reviews'] / (df['total_purchases'] + 1)\n",
        "df['engagement_score'] = (df['website_visits'] / 100) + (df['customer_reviews'] / 10)\n",
        "\n",
        "print(\"\\nNew Features Created:\")\n",
        "print(df[['customer_lifetime_value', 'purchase_velocity', 'recent_purchase']].head())\n",
        "\n",
        "# ===== DATA PREPROCESSING =====\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_cols = ['gender', 'product_preference', 'device_type', 'newsletter_subscribed']\n",
        "\n",
        "df_encoded = df.copy()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Drop non-numeric and target columns\n",
        "X = df_encoded.drop(['customer_id', 'purchase_frequency'], axis=1)\n",
        "y = df_encoded['purchase_frequency']\n",
        "\n",
        "# Encode target variable\n",
        "le_target = LabelEncoder()\n",
        "y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "print(\"\\nFeature Columns:\", X.columns.tolist())\n",
        "print(\"Target Classes:\", le_target.classes_)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded,\n",
        "                                                      test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining Set Size: {X_train.shape}\")\n",
        "print(f\"Test Set Size: {X_test.shape}\")\n",
        "\n",
        "# ===== MODEL BUILDING AND EVALUATION =====\n",
        "\n",
        "# 1. Logistic Regression (Baseline)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"LOGISTIC REGRESSION MODEL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
        "lr_precision = precision_score(y_test, lr_pred, average='weighted', zero_division=0)\n",
        "lr_recall = recall_score(y_test, lr_pred, average='weighted', zero_division=0)\n",
        "lr_f1 = f1_score(y_test, lr_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"Precision: {lr_precision:.4f}\")\n",
        "print(f\"Recall: {lr_recall:.4f}\")\n",
        "print(f\"F1-Score: {lr_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, lr_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, lr_pred, target_names=le_target.classes_))\n",
        "\n",
        "# 2. Random Forest Classifier (Advanced)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RANDOM FOREST CLASSIFIER MODEL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "rf_precision = precision_score(y_test, rf_pred, average='weighted', zero_division=0)\n",
        "rf_recall = recall_score(y_test, rf_pred, average='weighted', zero_division=0)\n",
        "rf_f1 = f1_score(y_test, rf_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1-Score: {rf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, rf_pred, target_names=le_target.classes_))\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# Visualize Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10), palette='viridis')\n",
        "plt.title('Top 10 Feature Importance (Random Forest)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.show()\n",
        "\n",
        "# ===== GRADIO DEPLOYMENT =====\n",
        "\n",
        "# Best model selection (Random Forest)\n",
        "best_model = rf_model\n",
        "best_scaler = scaler\n",
        "best_le_target = le_target\n",
        "\n",
        "def predict_purchase_frequency(age, gender, total_purchases, total_spend,\n",
        "                               avg_order_value, tenure_months, website_visits,\n",
        "                               cart_abandonment_rate, product_preference,\n",
        "                               device_type, newsletter, reviews, last_purchase_days):\n",
        "    \"\"\"\n",
        "    Predict customer purchase frequency based on input features\n",
        "    \"\"\"\n",
        "\n",
        "    # Create input dataframe\n",
        "    input_data = pd.DataFrame({\n",
        "        'age': [age],\n",
        "        'gender': [gender],\n",
        "        'total_purchases': [total_purchases],\n",
        "        'total_spend': [total_spend],\n",
        "        'avg_order_value': [avg_order_value],\n",
        "        'customer_tenure_months': [tenure_months],\n",
        "        'website_visits': [website_visits],\n",
        "        'cart_abandonment_rate': [cart_abandonment_rate],\n",
        "        'product_preference': [product_preference],\n",
        "        'device_type': [device_type],\n",
        "        'newsletter_subscribed': [newsletter],\n",
        "        'customer_reviews': [reviews],\n",
        "        'last_purchase_days_ago': [last_purchase_days],\n",
        "        'customer_lifetime_value': [total_spend / (tenure_months + 1)],\n",
        "        'purchase_velocity': [total_purchases / (tenure_months + 1)],\n",
        "        'recent_purchase': [1 if last_purchase_days <= 30 else 0],\n",
        "        'review_engagement_rate': [reviews / (total_purchases + 1)],\n",
        "        'engagement_score': [(website_visits / 100) + (reviews / 10)]\n",
        "    })\n",
        "\n",
        "    # Encode categorical variables\n",
        "    input_encoded = input_data.copy()\n",
        "    for col in categorical_cols:\n",
        "        if col in input_encoded.columns:\n",
        "            input_encoded[col] = label_encoders[col].transform(input_encoded[col])\n",
        "\n",
        "    # Scale features\n",
        "    input_scaled = best_scaler.transform(input_encoded)\n",
        "\n",
        "    # Get prediction and probability\n",
        "    prediction = best_model.predict(input_scaled)\n",
        "    probabilities = best_model.predict_proba(input_scaled)\n",
        "\n",
        "    # Get class label\n",
        "    predicted_label = best_le_target.inverse_transform([prediction])\n",
        "\n",
        "    # Get confidence\n",
        "    confidence = max(probabilities) * 100\n",
        "\n",
        "    # Create output message\n",
        "    output = f\"**Predicted Purchase Frequency:** {predicted_label}\\n\\n**Confidence:** {confidence:.1f}%\\n\\n\"\n",
        "    output += \"**Probability Distribution:**\\n\"\n",
        "    for i, label in enumerate(best_le_target.classes_):\n",
        "        output += f\"- {label}: {probabilities[i]*100:.1f}%\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Create Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_purchase_frequency,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Age (years)\", value=35),\n",
        "        gr.Dropdown(['M', 'F'], label=\"Gender\"),\n",
        "        gr.Number(label=\"Total Purchases\", value=20),\n",
        "        gr.Number(label=\"Total Spend ($)\", value=5000),\n",
        "        gr.Number(label=\"Average Order Value ($)\", value=250),\n",
        "        gr.Number(label=\"Customer Tenure (months)\", value=24),\n",
        "        gr.Number(label=\"Website Visits\", value=150),\n",
        "        gr.Slider(0, 100, step=1, label=\"Cart Abandonment Rate (%)\", value=15),\n",
        "        gr.Dropdown(['Electronics', 'Fashion', 'Home', 'Beauty'],\n",
        "                   label=\"Product Preference\", value='Electronics'),\n",
        "        gr.Dropdown(['Mobile', 'Desktop', 'Tablet'],\n",
        "                   label=\"Device Type\", value='Desktop'),\n",
        "        gr.Dropdown(['Yes', 'No'], label=\"Newsletter Subscribed\", value='Yes'),\n",
        "        gr.Number(label=\"Customer Reviews\", value=10),\n",
        "        gr.Number(label=\"Last Purchase Days Ago\", value=15)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Prediction Result\"),\n",
        "    title=\"ðŸ›ï¸ Customer Purchase Frequency Predictor\",\n",
        "    description=\"Enter customer details to predict their purchase frequency category.\",\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "# Launch the app (uncomment to run)\n",
        "# interface.launch()\n",
        "\n",
        "print(\"\\nâœ… Model training and Gradio interface setup complete!\")\n",
        "print(\"To launch the app, uncomment the interface.launch() line at the end.\")\n"
      ]
    }
  ]
}